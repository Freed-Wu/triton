# TritonNvidiaGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit -->
### `ttng.async_tma_copy_global_to_local` (triton::nvidia_gpu::AsyncTMACopyGlobalToLocalOp)

_Copy data based on descriptor from global memory to local memory asynchronously_


Syntax:

```
operation ::= `ttng.async_tma_copy_global_to_local` $desc_ptr `[` $coord `]` $result `,` $barrier `,` $pred
              oilist(`cacheModifier` `=` $cache | `evictionPolicy` `=` $evict)
              attr-dict `:` qualified(type($desc_ptr)) `,` qualified(type($barrier)) `->` qualified(type($result))
```

This operation copies data from global memory to local memory
asynchronously.  This is analogue to tt.load except the data are copied to
local memory pointed by the memory descriptor instead of a distributed
tensor. The data copied depends on the global memory descriptor pointed to
by `desc_ptr`.

Traits: `VerifyTensorLayoutsTrait`

Interfaces: `MemoryEffectOpInterface`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>cache</code></td><td>::mlir::triton::CacheModifierAttr</td><td><details><summary>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6, 7</summary>{{% markdown %}}Enum cases:
* none (`NONE`)
* ca (`CA`)
* cg (`CG`)
* wb (`WB`)
* cs (`CS`)
* wt (`WT`)
* cv (`CV`){{% /markdown %}}</details></td></tr>
<tr><td><code>evict</code></td><td>::mlir::triton::EvictionPolicyAttr</td><td><details><summary>allowed 32-bit signless integer cases: 1, 2, 3</summary>{{% markdown %}}Enum cases:
* evict_normal (`NORMAL`)
* evict_first (`EVICT_FIRST`)
* evict_last (`EVICT_LAST`){{% /markdown %}}</details></td></tr>
<tr><td><code>isVolatile</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `desc_ptr` | Pointer type (`::mlir::triton::PointerType`) in Triton IR type system
| `coord` | variadic of 32-bit signless integer
| `barrier` | memory descriptor type (`::mlir::triton::gpu::MemDescType`) in Triton IR type system
| `result` | memory descriptor type (`::mlir::triton::gpu::MemDescType`) in Triton IR type system
| `pred` | 1-bit signless integer

### `ttng.async_tma_copy_local_to_global` (triton::nvidia_gpu::AsyncTMACopyLocalToGlobalOp)

_Copy data based on descriptor from local memory to global memory asynchronously_


Syntax:

```
operation ::= `ttng.async_tma_copy_local_to_global` $desc_ptr `[` $coord `]` $src
              attr-dict `:` qualified(type($desc_ptr)) `,` qualified(type($src))
```

This operation copies data from local memory to global memory
asynchronously.  This is analogue to tt.store except the data are copied from
local memory pointed by the memory descriptor instead of a distributed
tensor. The data copied depends on the global memory descriptor pointed to
by `desc_ptr`.

Traits: `VerifyTensorLayoutsTrait`

Interfaces: `MemoryEffectOpInterface`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `desc_ptr` | Pointer type (`::mlir::triton::PointerType`) in Triton IR type system
| `coord` | variadic of 32-bit signless integer
| `src` | memory descriptor type (`::mlir::triton::gpu::MemDescType`) in Triton IR type system

### `ttng.barrier_expect` (triton::nvidia_gpu::BarrierExpectOp)

_Signal a barrier of an expected number of bytes to be copied._


Syntax:

```
operation ::= `ttng.barrier_expect` $alloc `,` $size attr-dict `,` $pred `:` qualified(type($alloc))
```

This signal the barrier that `size` bytes are expected to be copied. The
associated barrier wait will block until the expected number of bytes are copied.

Traits: `VerifyTensorLayoutsTrait`

Interfaces: `MemoryEffectOpInterface`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>size</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `alloc` | memory descriptor type (`::mlir::triton::gpu::MemDescType`) in Triton IR type system
| `pred` | 1-bit signless integer

### `ttng.cluster_arrive` (triton::nvidia_gpu::ClusterArriveOp)

Syntax:

```
operation ::= `ttng.cluster_arrive` attr-dict
```


Traits: `VerifyTensorLayoutsTrait`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>relaxed</code></td><td>::mlir::IntegerAttr</td><td>1-bit signless integer attribute</td></tr>
</table>

### `ttng.cluster_wait` (triton::nvidia_gpu::ClusterWaitOp)

Syntax:

```
operation ::= `ttng.cluster_wait` attr-dict
```


Traits: `VerifyTensorLayoutsTrait`

### `ttng.fence_async_shared` (triton::nvidia_gpu::FenceAsyncSharedOp)

_Fence proxy async_


Syntax:

```
operation ::= `ttng.fence_async_shared` attr-dict
```


Traits: `VerifyTensorLayoutsTrait`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>bCluster</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>

### `ttng.init_barrier` (triton::nvidia_gpu::InitBarrierOp)

_Initialize a barrier in the given shared memory allocation._


Syntax:

```
operation ::= `ttng.init_barrier` $alloc `,` $count attr-dict `:` qualified(type($alloc))
```

Initializes a shared memory allocation with mbarrier information.
`alloc` is a descriptor to the shared memory allocation. `count` is the
number of arrives expected by the barrier.

This lowers to PTX mbarrier.init.shared::cta.b64.

Traits: `VerifyTensorLayoutsTrait`

Interfaces: `MemoryEffectOpInterface`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>count</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `alloc` | memory descriptor type (`::mlir::triton::gpu::MemDescType`) in Triton IR type system

### `ttng.inval_barrier` (triton::nvidia_gpu::InvalBarrierOp)

_Invalidate a barrier allocation._


Syntax:

```
operation ::= `ttng.inval_barrier` $alloc attr-dict `:` qualified(type($alloc))
```

Invalidate a barrier allocation so that it can be re-used. According to PTX
spec this has to be done before any reuse of the memory used by mbarrier.

https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-inval

Traits: `VerifyTensorLayoutsTrait`

Interfaces: `MemoryEffectOpInterface`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `alloc` | memory descriptor type (`::mlir::triton::gpu::MemDescType`) in Triton IR type system

### `ttng.async_tma_store_wait` (triton::nvidia_gpu::TMAStoreWait)

_Wait until all the inputs are read._


Syntax:

```
operation ::= `ttng.async_tma_store_wait` attr-dict
```

Wait until all the read operations are done from the associated store operations.
This is needed before the shared memory can be written to.

Traits: `VerifyTensorLayoutsTrait`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>pendings</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>

### `ttng.tensor_desc_to_tma_ptr` (triton::nvidia_gpu::TensorDescToTMAPtrOp)

_Convert tensor descriptor to pointer to tma descriptor_


Syntax:

```
operation ::= `ttng.tensor_desc_to_tma_ptr` $desc attr-dict `:` qualified(type($desc)) `to` qualified(type($ptr))
```


Traits: `AlwaysSpeculatableImplTrait`, `VerifyTensorLayoutsTrait`

Interfaces: `ConditionallySpeculatable`, `NoMemoryEffect (MemoryEffectOpInterface)`

Effects: `MemoryEffects::Effect{}`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `desc` | Tensor descriptor type (`::mlir::triton::TensorDescType`) in Triton IR type system

#### Results:

| Result | Description |
| :----: | ----------- |
| `ptr` | ptr

### `ttng.wait_barrier` (triton::nvidia_gpu::WaitBarrierOp)

_Wait until the mbarrier phase completes._


Syntax:

```
operation ::= `ttng.wait_barrier` $alloc `,` $phase attr-dict `:` qualified(type($alloc))
```

Blocks the program progress until the mbarrier object in `alloc` completes
its current phase.

This lowers a waitloop using PTX instruction
mbarrier.try_wait.parity.shared.b64.

The barrier behavior is described here:
https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms

Traits: `VerifyTensorLayoutsTrait`

Interfaces: `MemoryEffectOpInterface`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `alloc` | memory descriptor type (`::mlir::triton::gpu::MemDescType`) in Triton IR type system
| `phase` | 32-bit signless integer

### `ttng.warp_group_dot` (triton::nvidia_gpu::WarpGroupDotOp)

_Warp group dot_


Syntax:

```
operation ::= `ttng.warp_group_dot` $a`,` $b`,` $c (`,` $useC^)? attr-dict `:` type($a) `*` type($b) `->` type($d)
```

$d = matrix_multiply($a, $b) + $c. For docs on InputPrecisionAttr, see TT_DotOp

Traits: `DotLike`, `VerifyTensorLayoutsTrait`

Interfaces: `InferTypeOpInterface`, `MemoryEffectOpInterface`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>inputPrecision</code></td><td>::mlir::triton::InputPrecisionAttr</td><td><details><summary>allowed 32-bit signless integer cases: 0, 1, 2</summary>{{% markdown %}}Enum cases:
* tf32 (`TF32`)
* tf32x3 (`TF32x3`)
* ieee (`IEEE`){{% /markdown %}}</details></td></tr>
<tr><td><code>maxNumImpreciseAcc</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
<tr><td><code>isAsync</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `a` | TensorOrMemDesc instance
| `b` | TensorOrMemDesc instance
| `c` | ranked tensor of floating-point or integer values
| `useC` | 1-bit signless integer

#### Results:

| Result | Description |
| :----: | ----------- |
| `d` | ranked tensor of floating-point or integer values

### `ttng.warp_group_dot_wait` (triton::nvidia_gpu::WarpGroupDotWaitOp)

_Warp group dot wait_


Syntax:

```
operation ::= `ttng.warp_group_dot_wait` $inputs attr-dict `:` type($inputs)
```

Waits until there are $pendings or fewer outstanding async dot operations.

$inputs must be the tensors corresponding to the async dot ops that we're
waiting on.  For example, if there are N pending async dot ops and we call
`warp_group_dot_wait 1`, then $inputs must be the result of the first dot op.

Traits: `VerifyTensorLayoutsTrait`

Interfaces: `InferTypeOpInterface`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>pendings</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `inputs` | variadic of TensorOrMemDesc instance

#### Results:

| Result | Description |
| :----: | ----------- |
| `outputs` | variadic of TensorOrMemDesc instance

